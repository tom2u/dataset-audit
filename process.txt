There are 3 repos containing unidentified data sets:

DataViz-Lesson-Plans
DataViz-Lesson-Plans-v1.1
DataViz-Online
nflx-adv-data

There are 3 file types in the repos that will contain the data sets:

*.csv
*.xls
*.json

Step 1: clone each repo locally in dedicated Audit-project folder
Step 2: in the root of each repo, create a listing of each matching file type found in the repo:

dir /b /s /n *.csv > csv.txt
dir /b /s /n *.xls > xls.txt
dir /b /s /n *.json > json.txt

This creates a listing with full file names:

DataViz-Lesson-Plans\01-Lesson-Plans\01-Excel\1\Activities\01-Ins_GreatDebate\Resources\Census_Data.csv
DataViz-Lesson-Plans\01-Lesson-Plans\02-VBA-Scripting\3\Activities\07-Stu_WellsFargo_Pt1\Unsolved\RAW\Alabama_Wells_Fargo_Bank_Deposits.csv
DataViz-Lesson-Plans\01-Lesson-Plans\02-VBA-Scripting\3\Activities\07-Stu_WellsFargo_Pt1\Unsolved\RAW\Alaska_Wells_Fargo_Bank_Deposits.csv

We need to compare files to eliminate duplicates. Duplicates may exist across the repos.

Step 3: Concatenate the files into dedicated master-*.txt files in the main Audit-project folder:

copy dataviz-lesson-plans\csv.txt + dataviz-online\csv.txt + nflx-adv-data\csv.txt master-csv.txt
copy dataviz-lesson-plans\xls.txt + dataviz-online\xls.txt + nflx-adv-data\xls.txt master-xls.txt
copy dataviz-lesson-plans\json.txt + dataviz-online\json.txt + nflx-adv-data\json.txt master-json.txt

Step 4: Run the following batch file (saved as copy-files-to-master-folders.bat). It copies each data file referenced in the *.txt files created in the steps above into folders with the same names as the *.txt files.

NOTE: Each copied file receives a prefix that corresponds to the line number on which it was found in the original *.txt file:

==========
@echo off
cls
setlocal

rem Set each folder/file name in a separate array variable (not true arrays, but just go with it for now...)
set target[0]=master-json
set target[1]=master-csv
set target[2]=master-xls

for /F "tokens=2 delims==" %%t in ('set target[') do (

	set directory=%%t
	del /q %directory%\*.*

	setlocal EnableDelayedExpansion
	set /a Counter=0

	for /F "usebackq delims=" %%a in (`"findstr /b ^^ %%t.txt"`) do (

rem Write line text to tempfile:
		echo %%a> tempfile.txt
rem Capture line length from text file length in strlength variable:
		for %%? in (tempfile.txt) do ( set /A strlength=%%~z? - 2 )

		set /a Counter+=1
		set "source=%%a"
		set "source=!source:*:=!"

		if not "!strlength!"=="1" (
			if not "!strlength!"=="0" (
				for %%i in ("!source!") do (
					set filename=%%~ni
					set extension=%%~xi
					set destination=!directory!\!Counter!-!filename!!extension!
				)
				echo !destination!
				copy "!source!" "!destination!" >nul
			)
		)
	)
	endlocal
)

endlocal

=========

Now we have these folders:

master-json
master-csv
master-xls

Each has the corresponding file types within it, each file prefixed with the line number it was found on in the corresponding master-* file. 

For example, master-csv begins with these three files:

1-Census_Data.csv
2-Alabama_Wells_Fargo_Bank_Deposits.csv
3-Alaska_Wells_Fargo_Bank_Deposits.csv

Those are copies of the same files referenced in lines 1, 2, and 3 of the master-csv.txt file:

DataViz-Lesson-Plans\01-Lesson-Plans\01-Excel\1\Activities\01-Ins_GreatDebate\Resources\Census_Data.csv
DataViz-Lesson-Plans\01-Lesson-Plans\02-VBA-Scripting\3\Activities\07-Stu_WellsFargo_Pt1\Unsolved\RAW\Alabama_Wells_Fargo_Bank_Deposits.csv
DataViz-Lesson-Plans\01-Lesson-Plans\02-VBA-Scripting\3\Activities\07-Stu_WellsFargo_Pt1\Unsolved\RAW\Alaska_Wells_Fargo_Bank_Deposits.csv

Next we'll create a filtered/sorted archive of the files, grouping all matching files into the same folder. If a file is distinct, i.e., it has no duplicates, it will be the only file in the folder. But if there are duplicate files, they will be grouped with it in the same folder.

=========

@echo off
REM
REM Copy a file to a dedicated folder.
REM Compare it to all other files.
REM Copy all duplicate files to the same folder.
REM Remove all corresponding files from the source master-* folder so that the files are not 
REM used for redundant processing subsequently.
REM
rem How to free up extra disk space: 
rem https://techcommunity.microsoft.com/t5/windows-it-pro-blog/managing-reserved-storage-in-windows-10-environments/ba-p/1297070


cls

setlocal EnableDelayedExpansion

set DT=!DATE! !TIME!
set year=!DT:~10,4!
set day=!DT:~4,2!
set mth=!DT:~7,2!
set hour=!DT:~15,2!
set min=!DT:~18,2!
set sec=!DT:~21,2!
set hun=!DT:~24,2!

echo Start Time = !hour!:!min!:!sec!:!hun!

rem Set each folder/file name in a separate array variable (not true arrays, but just go with it for now...)
set target[0]=master-json
set target[1]=master-csv
set target[2]=master-xls


for /F "tokens=2 delims==" %%a in ('set target[') do (

	set folder=%%a
	set "extension=!folder:*-=!"
	set sorted_folder=sorted-!extension!
	set /a counter=0

	if exist !sorted_folder! (
		del /q !sorted_folder!\*
		FOR /D %%p IN ("!sorted_folder!\*.*") DO rmdir "%%p" /s /q
	)

	if not exist !sorted_folder! mkdir !sorted_folder!

	echo ^*^*^*^*^*^*^*^*^*^*^*^*^*^*
	echo FOLDER: !folder!
	echo EXTENSION: !extension!


	for /r %%i in (!folder!\*.!extension!) do (

		set subject_file=%%i
		if exist "!subject_file!" (

			set /a counter+=1
			echo ---------------------------
			echo Subfolder: !sorted_folder!\!counter!

			if exist !sorted_folder!\!counter! (
				del /q !sorted_folder!\!counter!\*
				FOR /D %%p IN ("!sorted_folder!\!counter!\*.*") DO rmdir "%%p" /s /q
			)

			if not exist !sorted_folder!\!counter! mkdir !sorted_folder!\!counter!

			copy "!subject_file!" !sorted_folder!\!counter!

			for %%S in (!subject_file!) do (
				set subject_size=%%~zS
			)

			echo Subject:
			echo !subject_file!

			for /r %%j in (!folder!\*.!extension!) do (

				set comparison_file=%%j
				echo ^* !comparison_file!

				for %%C in (!comparison_file!) do (
					set comparison_size=%%~zC
				)

				if exist "!comparison_file!" (
					if not "!comparison_file!"=="!subject_file!" (
						if "!comparison_size!"=="!subject_size!" (

							fc /B "!subject_file!" "!comparison_file!" > stats.txt
							findstr /m /c:"no differences encountered" stats.txt >nul

							if !errorlevel!==0 (
								echo Match:
								echo !comparison_file!
								copy "!comparison_file!" !sorted_folder!\!counter!
								del /q !comparison_file!
							)
						)
					)
				)
			)

			del /q "!subject_file!"

		)
	)
)


REM ***************************************
REM Get the hours/min/secs/hun, etc from current date and time
REM ***************************************
set EndTime=!TIME!
set EndHour=!EndTime:~0,2!
set EndMin=!EndTime:~3,2!
set EndSec=!EndTime:~6,2!
set EndHun=!EndTime:~9,2!

REM *******************************
REM Calculate the difference
REM Hours, Minutes, seconds, hundredths calculated separately
REM *******************************
set /a Hour_Diff=EndHour-hour
set /a Min_Diff=EndMin-min
set /a Sec_Diff=EndSec-sec
set /a Hun_Diff=EndHun-hun

REM *******************************
REM Carry any differences
REM *******************************

IF !Hun_Diff! LSS 0 (
	set /a Hun_Diff=Hun_Diff+100
	set /a Sec_Diff=Sec_Diff+1
)

IF !Sec_Diff! LSS 0 (
	set /a Sec_Diff=Sec_Diff+60
	set /a Min_Diff=Min_Diff+1
)

If !Min_Diff! LSS 0 (
	set /a Min_Diff=Min_Diff+60
	set /a Hour_Diff=Hour_Diff+1
)

echo Start Time = !hour!:!min!:!sec!:!hun!
echo End Time = !EndHour!:!EndMin!:!EndSec!:!EndHun!
echo.

endlocal

=========

Now we have these folders:

sorted-json
sorted-csv
sorted-xls

In each folder is a series of consecutively numbered folders:

sorted-csv/1
sorted-csv/2
sorted-csv/3

etc.

Each folder contains at least one data file. If there are multiple files, they are exact duplicates of each other. The numbers prefixing each file indicate on which line number in the corresponding master-* text file that the source file--with its original repo URL--is located.

For example:

sorted-csv/4 contains these files.

101-used_cars.csv
434-used_cars.csv
534-used_cars.csv

In master-json.txt, lines 101, 434, and 534 are respectively:

DataViz-Lesson-Plans\01-Lesson-Plans\05-Matplotlib\2\Activities\04-Ins_GroupPlots\Resources\used_cars.csv
DataViz-Online\03-Lesson-Plans\05-Lessons\2\Activities\04-Ins_GroupPlots\Resources\used_cars.csv
nflx-adv-data\01-Lesson-Plans\03-Matplotlib\01-Day\Activities\11-Ins_GroupPlots\Resources\used_cars.csv

Next, run create-dataset-sources-files.bat, which will write this data to individual rows in new CSV files. In the case of the previous example, the 4th row of the created file would be:

,DataViz-Lesson-Plans\01-Lesson-Plans\05-Matplotlib\2\Activities\04-Ins_GroupPlots\Resources\used_cars.csv,DataViz-Online\03-Lesson-Plans\05-Lessons\2\Activities\04-Ins_GroupPlots\Resources\used_cars.csv,nflx-adv-data\01-Lesson-Plans\03-Matplotlib\01-Day\Activities\11-Ins_GroupPlots\Resources\used_cars.csv

The first cell of the CSV is always empty. It is where the URL of the data source will be recorded. Each succeeding cell in the row will be each URL of the each duplicate data set found by the previous routines.

For example, the first 3 rows of the csv-dataset-sources.csv file are:

,DataViz-Lesson-Plans\01-Lesson-Plans\01-Excel\1\Activities\01-Ins_GreatDebate\Resources\Census_Data.csv  
,DataViz-Lesson-Plans\01-Lesson-Plans\02-VBA-Scripting\3\Activities\07-Stu_WellsFargo_Pt1\Unsolved\RAW\Florida_Wells_Fargo__Bank_Deposits.csv  
,DataViz-Lesson-Plans\01-Lesson-Plans\05-Matplotlib\2\Activities\03-Stu_BattlingKings-PlottingPandas\Unsolved\Resources\got.csv ,DataViz-Online\03-Lesson-Plans\05-Lessons\2\Activities\03-Stu_BattlingKings-PlottingPandas\Solved\Resources\got.csv ,DataViz-Online\03-Lesson-Plans\05-Lessons\2\Activities\03-Stu_BattlingKings-PlottingPandas\Unsolved\Resources\got.csv ,DataViz-Lesson-Plans\01-Lesson-Plans\05-Matplotlib\2\Activities\03-Stu_BattlingKings-PlottingPandas\Solved\Resources\got.csv  

These correspond to the files in the folders sorted-csv/1, sorted-csv/2, sorted-csv/3.

Next, use auto-open-chrome.bat. 
* Set the extension variable at the top (=csv, xls, json)
* Set the starting number to the first folder to open (so you can quit the process and return to start it at the line where you left off)

It will collect the first and second lines in the first file in each folder.
Those lines will be used as search queries in Google
Add the URL of the dataset to the first column in each row of *-dataset-sources.csv